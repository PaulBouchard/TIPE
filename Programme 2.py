## Importation des modules
import pandas as pd
import seaborn as sns
import ast

from sklearn.tree import DecisionTreeClassifier,plot_tree
from sklearn.model_selection import train_test_split
from sklearn import metrics,svm
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression

## acquisition du fichier csv et manipulation pour y incorporer une colonne de diagnostics
# Chemin à écrire devant le nom des fichiers dépendant d'où ils se situent
chemin="D:\\"

# On charge la base de données dans Y
Y = pd.read_csv(chemin+'ptbxl_database.csv')
Y=Y.drop(['ecg_id'],axis=1)
Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))

# On charge le fichier scp_statements pour en garder les diagnostics
tab_diag = pd.read_csv(chemin+'scp_statements.csv', index_col=0)
tab_diag = tab_diag[tab_diag.diagnostic == 1]

def aggregate_diagnostic(y_dic):
    tmp = []
    for key in y_dic.keys():
        if key in tab_diag.index:
            tmp.append(tab_diag.loc[key].diagnostic_class)
    return list(set(tmp))

# On ajoute la colonne des diagnostics
Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)

## On manipule les colonnes et lignes pour obtenir un DataFrame correct (= comporte uniquement des entiers/flottants et aucune 'case' vide

# On retire les colonnes inutiles ou trop incomplètes
Y = Y.drop(['patient_id','recording_date', 'report', 'scp_codes','infarction_stadium1', 'infarction_stadium2','baseline_drift', 'static_noise', 'burst_noise', 'electrodes_problems','extra_beats', 'pacemaker','filename_lr', 'filename_hr'],axis=1)

# On remplace les False par 0 et les True par 1
L=['second_opinion','initial_autogenerated_report','validated_by_human']
for e in L:
    for i in range(len(Y['second_opinion'])):
        if Y.at[i,e] == False:
            Y.at[i,e]=0
        else:
            Y.at[i,e]=1

# on remplace les valeurs dans les listes par des entiers consécutifs pour pouvoir utiliser ces colonnes dans la prédiction
# éléments de la colonne device
L1=['CS-12   E', 'AT-6 C 5.0', 'AT-6 C', 'CS-12', 'AT-6 C 5.5', 'AT-6 C 5.8', 'AT-6 C 5.6', 'AT-6     6', 'AT-6 C 5.3', 'AT-60    3', 'CS100    3']

# éléments de la colonne heart_axis
L2=['LAD', 'ALAD', 'RAD', 'AXR', 'MID', 'ARAD', 'AXL', 'SAG']

for i in range(len(Y['device'])):
    for j in range(len(L1)):
        if Y.at[i,'device']==L1[j]:
            Y.at[i,'device']=j

for i in range(len(Y['heart_axis'])):
    for j in range(len(L2)):
        if Y.at[i,'heart_axis']==L2[j]:
            Y.at[i,'heart_axis']=j

# on remplace tout ce qui n'est pas ['NORM'] (= rien d'anormal) par 1 et ['NORM'] par 0
for i in range(len(Y['diagnostic_superclass'])):
    if Y.at[i,'diagnostic_superclass']==['NORM']:
        Y.at[i,'diagnostic_superclass']=0
    else:
        Y.at[i,'diagnostic_superclass']=1

# On retire les lignes qui comportent une case vide puis on envoie le DataFrame dans un nouveau fichier csv pour faire correspondre les numéros de ligne
Y=Y.dropna()
Y.to_csv(chemin+'ptbxl_database_2.csv')
Y=pd.read_csv(chemin+'ptbxl_database_2.csv')
Y=Y.drop(['Unnamed: 0'],axis=1)

# On rend les valeurs entières (on ne travaille pas avec des flottants)
Y=Y.astype('int')

## Machine learning
# on scinde Y en 2 matrices
x = Y.drop('diagnostic_superclass', axis=1)
y = Y['diagnostic_superclass']

x_entrainement, x_test, y_entrainement, y_test = train_test_split(x,y,test_size= 0.3)
DT = DecisionTreeClassifier()
LR = LogisticRegression(solver="liblinear")
sv = svm.SVC()
modele1 = sv.fit(x_entrainement,y_entrainement)
modele2 = LR.fit(x_entrainement,y_entrainement)
modele3 = DT.fit(x_entrainement,y_entrainement)

y_pred = modele1.predict(x_test)
print("Précision:",metrics.accuracy_score(y_test, y_pred))
y_pred = modele2.predict(x_test)
print("Précision:",metrics.accuracy_score(y_test, y_pred))
y_pred = modele3.predict(x_test)
print("Précision:",metrics.accuracy_score(y_test, y_pred))

# On crée un arbre de décision
plt.close()
plot_tree(DT, feature_names=['age', 'sex', 'height', 'weight', 'nurse', 'site', 'device',
       'heart_axis', 'validated_by', 'second_opinion',
       'initial_autogenerated_report', 'validated_by_human', 'strat_fold'], class_names=['pas malade','malade'],filled=True)
plt.show()

## Moyenne
i,j,k=0,0,0
for p in range(100):
    X_entrainement, X_test, Y_entrainement, Y_test =train_test_split(x,y,test_size= 0.25)
    modele1 = sv.fit(X_entrainement,Y_entrainement)
    modele2 = LR.fit(X_entrainement,Y_entrainement)
    modele3 = DT.fit(X_entrainement,Y_entrainement)
    Y_pred1 = modele1.predict(X_test)
    Y_pred2 = modele2.predict(X_test)
    Y_pred3 = modele3.predict(X_test)
    i=i+metrics.accuracy_score(Y_test,Y_pred1)
    j=j+metrics.accuracy_score(Y_test,Y_pred2)
    k=k+metrics.accuracy_score(Y_test,Y_pred3)
print((100*i)/100)
print((100*j)/100)
print((100*k)/100)